{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600195076356",
   "display_name": "Python 3.6.9 64-bit ('venv': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from test_dataset import Test_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config = {\"batch_size\": 41}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_prediction(arr):\n",
    "    arr_reshaped = arr.reshape(-1, 1)\n",
    "    return np.clip(np.concatenate((1.0 - arr_reshaped, arr_reshaped), axis=1), 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(df, root_dir, mode):\n",
    "    model = timm.create_model(\"tf_efficientnet_b4_ns\", pretrained=False, num_classes=1)\n",
    "    if mode == \"random_erase\":\n",
    "        model.load_state_dict(torch.load(\"weights/random_erase_tf_efficientnet_b4_ns.h5\"))\n",
    "    elif mode == \"face_cutout\":\n",
    "        model.load_state_dict(torch.load(\"weights/face_cutout_tf_efficientnet_b4_ns.h5\"))\n",
    "    model.to(device)\n",
    "\n",
    "    data = Test_Dataset(df, root_dir)\n",
    "    data_loader = DataLoader(\n",
    "        data,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        num_workers=8,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            batch_images = batch[\"image\"].to(device)\n",
    "            batch_labels = batch[\"label\"].to(device)\n",
    "\n",
    "            out = model(batch_images)\n",
    "\n",
    "            batch_targets = (batch_labels.view(-1, 1).cpu() >= 0.5) * 1\n",
    "            batch_preds = torch.sigmoid(out).cpu()\n",
    "\n",
    "            targets.append(batch_targets)\n",
    "            predictions.append(batch_preds)\n",
    "\n",
    "        targets = np.vstack((targets)).ravel()\n",
    "        predictions = np.vstack((predictions)).ravel()\n",
    "\n",
    "        auc = metrics.roc_auc_score(targets, predictions)\n",
    "        mAP = metrics.average_precision_score(targets, predictions)\n",
    "        log_loss = metrics.log_loss(targets, expand_prediction(predictions))\n",
    "\n",
    "        print('')\n",
    "        print(f\"AUC : {auc}\")\n",
    "        print(f\"mAP : {mAP}\")\n",
    "        print(f\"LogLoss : {log_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Face Cutout --------------\n100%|██████████| 40/40 [00:05<00:00,  8.04it/s]\n\nAUC : 0.9659584773104254\nmAP : 0.9927165331395946\nLogLoss : 0.2119294066442086\n\nRandom Erase -------------\n100%|██████████| 40/40 [00:05<00:00,  8.10it/s]\nAUC : 0.9448474498375792\nmAP : 0.988081434519885\nLogLoss : 0.24963293145048693\n\n"
    }
   ],
   "source": [
    "df = pd.read_csv(\"metadata.csv\")\n",
    "\n",
    "print(\"Face Cutout --------------\")\n",
    "validate(df, root_dir=\"data/val_images\", mode=\"face_cutout\")\n",
    "print()\n",
    "print(\"Random Erase -------------\")\n",
    "validate(df, root_dir=\"data/val_images\", mode=\"random_erase\")"
   ]
  }
 ]
}